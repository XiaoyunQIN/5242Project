# Image Captioning

Xinze Liu(xl2822), Kun Liang(kl3056), Ting Cai(tc2945), Xiaoyun Qin(xq2189)

This is a repo for our group project - Image Captioning. 

It contains a .ipynb document that contains our final model with experiments we had tried, and some sample images captioning generated by our model with the origial human written captions. The .h5 file contains our model is over 200 MB, so we will include it here.

In this project, we presented three different implementations on an encoder-decoder base model, which are the base model with multi LSTM layers, the base model that uses the pre-train GloVe word vectors, and the base model with the attention mechanism to generate descriptions of the images. We implemented all the models on the flickr8k data set and compare their performances through the BLEU score.

The base model with the attention mechanism has the best performance with BLEU-1 = 0.594
